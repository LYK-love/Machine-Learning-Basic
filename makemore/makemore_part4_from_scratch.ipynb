{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline\n",
    "\n",
    "'''\n",
    "Insprired by [Building makemore Part 4: Becoming a Backprop Ninja](https://www.youtube.com/watch?v=q8SA3rM6ckI&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=5&t=5798s).\n",
    "The author's notebook is [here](https://github.com/karpathy/nn-zero-to-hero/blob/master/lectures/makemore/makemore_part4_backprop.ipynb).\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
     ]
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "print(len(words))\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok biolerplate done, now we get to the action:\n",
    "\n",
    "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "  ex = torch.all(dt == t.grad).item()\n",
    "  app = torch.allclose(dt, t.grad)\n",
    "  maxdiff = (dt - t.grad).abs().max().item()\n",
    "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1 # using b1 just for fun, it's useless because of BN\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "# Note: I am initializating many of these parameters in non-standard ways\n",
    "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass.\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # a shorter variable also, for convenience\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3427, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[Xb] # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "# BatchNorm layer\n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact) # hidden layer\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "  p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "         embcat, emb]:\n",
    "  t.retain_grad()\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 30]), torch.Size([27, 10]), torch.Size([32, 3]))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embcat.shape, C.shape, Xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hpreact         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bngain          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnbias          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnraw           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar_inv       | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff2         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnmeani         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hprebn          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "embcat          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "emb             | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "C               | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: backprop through the whole thing manually, \n",
    "# backpropagating through exactly all of the variables \n",
    "# as they are defined in the forward pass above, one by one\n",
    "\n",
    "# Here, d{x} means the grad of variable x, equaling to: (the local grad of x) * (the upstream grad of x)\n",
    "dloss = 1\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = - 1.0 / n # f(x) = ln x, df / dx = 1/x\n",
    "dprobs = (1.0 / probs) * dlogprobs\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True) # counts_sum_inv.shape = [31,1], we nned to keep the shape\n",
    "dcounts_sum = -1 * (counts_sum ** (-2)) * dcounts_sum_inv\n",
    "dcounts = counts_sum_inv * dprobs # [32,1] * [32*27] (broadcasting) => [32,27] * [32*27] \n",
    "dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "dnorm_logits = counts * dcounts # norm_logits: [32,27]. counts == norm_logits.exp()\n",
    "dlogit_maxes = ((-1  * torch.ones_like(logit_maxes) ) * dnorm_logits ).sum(1, keepdim=True) # dnorm_logits: [32,27]\n",
    "dlogits = torch.ones_like(norm_logits) * dnorm_logits\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes # logits.max(1).indices extracts the tensor of indices of the maximum logit values along dimension 1 (across the 27 classes for each example).\n",
    "dh = dlogits @ W2.T # [32, 27] * [27,64] ==> [32,64]\n",
    "dW2 = h.T @ dlogits # [64, 32] * [32,27] ==> [64,27]\n",
    "db2 = dlogits.sum(0, keepdim=False) # [32,27]. Since b2 has shape [27], we need to use `keepdim=False` to squeeze [27,1] to be [27]\n",
    "dhpreact = (1 - h**2) * dh # d tanh(x) / d x = 1 - tanh(x)**2. Every tensor here has shape [32,64].\n",
    "dbngain = (dhpreact * bnraw).sum(0, keepdim=True)\n",
    "dbnbias = dhpreact.sum(0, keepdim=True) # Since bnbias has shape [27,1], we should use `keepdim=True` to keep the shape.\n",
    "dbnraw = bngain * dhpreact # bngain (shape=[1, 64]) is broadcasted to have shape [32,64], then multiply with dhpreact(shape=[32,64])\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "dbnvar = -0.5 * ((bnvar + 1e-5) ** -1.5) * dbnvar_inv\n",
    "dbndiff2 = torch.ones_like(bndiff2) * (1/(n-1)) * dbnvar\n",
    "dbndiff = bnvar_inv * dbnraw\n",
    "dbndiff += 2 * bndiff * dbndiff2\n",
    "dbnmeani = -dbndiff.sum(0, keepdim=True)\n",
    "dhprebn = 1.0 * dbndiff.clone()\n",
    "dhprebn += 1/n * dbnmeani\n",
    "dembcat = dhprebn @ W1.T\n",
    "dW1 = embcat.T @ dhprebn\n",
    "db1 = dhprebn.sum(0, keepdim=False)\n",
    "demb = dembcat.view(emb.shape)\n",
    "dC = torch.zeros_like(C) # Can't understand\n",
    "for k in range(Xb.shape[0]):\n",
    "  for j in range(Xb.shape[1]):\n",
    "    ix = Xb[k,j]\n",
    "    dC[ix] += demb[k,j]\n",
    "\n",
    "cmp('probs', dprobs, probs)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "cmp('counts', dcounts, counts)\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "cmp('logits', dlogits, logits)\n",
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)\n",
    "cmp('hpreact', dhpreact, hpreact)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "cmp('bnvar', dbnvar, bnvar)\n",
    "cmp('bndiff2', dbndiff2, bndiff2)\n",
    "cmp('bndiff', dbndiff, bndiff)\n",
    "cmp('bnmeani', dbnmeani, bnmeani)\n",
    "cmp('hprebn', dhprebn, hprebn)\n",
    "cmp('embcat', dembcat, embcat)\n",
    "cmp('W1', dW1, W1)\n",
    "cmp('b1', db1, b1)\n",
    "cmp('emb', demb, emb)\n",
    "cmp('C', dC, C)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3426623344421387 diff: -2.384185791015625e-07\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: backprop through cross_entropy but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the loss,\n",
    "# take the derivative, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "# counts = norm_logits.exp()\n",
    "# counts_sum = counts.sum(1, keepdims=True)\n",
    "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "# probs = counts * counts_sum_inv\n",
    "# logprobs = probs.log()\n",
    "# loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# now:\n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(loss_fast.item(), 'diff:', (loss_fast - loss).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: False | approximate: True  | maxdiff: 6.51925802230835e-09\n"
     ]
    }
   ],
   "source": [
    "dlogits = F.softmax(logits, 1)\n",
    "dlogits[range(n), Yb] -= 1\n",
    "dlogits /= n\n",
    "\n",
    "cmp('logits', dlogits, logits) # I can only get approximate to be true, my maxdiff is 6e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32]))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape, Yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x137bba090>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATMAAAFgCAYAAADXQp4HAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAkAElEQVR4nO3dfUxUZ9oG8AsVBlQYisrHVFDUim0VNutWSmxdW6nIJo1WmtiPZLUxGl1sVtluGzb93k3o2qR121D9p6tpUmvXpGraZDUtLZjuol1ZjWWtVCmKVsCWLszwTeG8f/g66yhwrsFDZ3y8fskkMtw+55lzxtszc+7nPhGWZVkQEbnBjQr1BEREnKBkJiJGUDITESMomYmIEZTMRMQISmYiYgQlMxExgpKZiBhhTKgncLX+/n5cuHABsbGxiIiICPV0RCSELMuCz+eDx+PBqFFDn3uFXTK7cOECUlNTQz0NEQkj586dw+TJk4eMGbFkVlpaildffRWNjY3IysrCm2++iXnz5tn+vdjYWADA0aNH/X8ezOjRo23H83q91HwjIyOpuJ6eHtuYuLg4aiyfz2cbw7xGAJg9ezYVV11dbRvDnhGzK+GY8fr7+x0bq7e3lxqLnT9zDNixYmJiqLi+vj7bGPZ1Mvts3Lhx1Fg//vgjFcf8O2GOeVtbG+bPn2+bC4ARSmbvv/8+ioqKsG3bNmRnZ2PLli3Iy8tDTU0NEhMTh/y7l3d8bGys7QsYM8Z++uybzMlkxux4FpvMWMzclMwCKZn9z0+dzC5jXsOIXAB47bXXsGbNGjzxxBO44447sG3bNowdOxZ//etfR2JzIiLOJ7Oenh5UVVUhNzf3fxsZNQq5ubmorKy8Jr67uxterzfgISISLMeT2ffff4++vj4kJSUFPJ+UlITGxsZr4ktKSuB2u/0PffkvIsMR8jqz4uJitLa2+h/nzp0L9ZRE5Abk+AWAiRMnYvTo0Whqagp4vqmpCcnJydfEu1wuuFwup6chIjcZx8/MoqKiMHfuXJSVlfmf6+/vR1lZGXJycpzenIgIgBEqzSgqKsLKlSvxi1/8AvPmzcOWLVvQ3t6OJ554YiQ2JyIyMslsxYoV+O677/D888+jsbERP/vZz7B///5rLgoMpa+vz7bWhqnFueWWW6jtdXR0UHFMbRs7FlObZLeE47JvvvmGimNqe5jXCPD1aE667bbbbGNOnTpFjcXWOTFx7L5g67SYOHabzPzZfdHV1UXFOVUDGsx7bMRWAGzYsAEbNmwYqeFFRAKE/GqmiIgTlMxExAhKZiJiBCUzETGCkpmIGEHJTESMoGQmIkYIu7bZl3V1ddk2TGQK6jo7O6ntsc31mCJWtuh07NixVByDbeLINM1jm/6x22T2Gdsc8+TJk7Yx6enp1FhscS1zPNmiU7fbTcUxhdfMsQS4+Ts5FuBs0S9LZ2YiYgQlMxExgpKZiBhByUxEjKBkJiJGUDITESMomYmIEZTMRMQISmYiYoSwXQEwatQo28pxpmo/KiqK2h5bzc5sk62gZ1soO4lpNc5W4zNjAVylN1tBz9zJ69tvv6XGYltAO9l2uq2tjYrr7u6m4hgzZsywjampqaHGYqv2mePkZAt3QGdmImIIJTMRMYKSmYgYQclMRIygZCYiRlAyExEjKJmJiBGUzETECGFbNDtnzhzbmNraWtsYtjCVjWMK/diiUycLcGNiYqg4Zm5sASgbxxQ+svufGcvj8VBjffPNN1RcdHS0bQy7L5gW4gB3nNhW10xBLNs2nn1vM3MLpiCWoTMzETGCkpmIGEHJTESMoGQmIkZQMhMRIyiZiYgRlMxExAhKZiJiBCUzETFC2K4AqK6uRmxs7HWPw7bNZtsBM5XSbDtmphqcrexn2ywzlersPmPbZjNxbDU40978/Pnz1FgsZt+yKwCmTp1KxTGrW9hW70wcu5qAjYuPj7eN6ejooMZiOX5m9uKLLyIiIiLgMWvWLKc3IyISYETOzO6880588skn/9uIw2uwRESuNiJZZsyYMUhOTh6JoUVEBjQiFwBOnToFj8eDadOm4fHHH0d9ff2gsd3d3fB6vQEPEZFgOZ7MsrOzsWPHDuzfvx9bt25FXV0d7r33Xvh8vgHjS0pK4Ha7/Y/U1FSnpyQiN4EIi21kNEwtLS2YMmUKXnvtNaxevfqa33d3dwdcLfJ6vUhNTdXVzP/H9o8KxdVM9soWczXNyStz7FVWdv5O3sQ4IyODimOuZrKcvJrJcupqps/nwx133IHW1lbExcUNGTvi38zHx8dj5syZOH369IC/d7lc1N2PRUSGMuJFs21tbaitrUVKSspIb0pEbmKOJ7OnnnoKFRUVOHPmDP75z3/ioYcewujRo/Hoo486vSkRET/HP2aeP38ejz76KJqbmzFp0iTcc889OHToECZNmhTUOJGRkbbfFzGfuZn+7cClM0gG8/0D+zUk890UOxZbyzdjxgzbmBMnTji6TSfvdcB8tzN27FhqLPbrDeb7SPY7Sye/C2O/T2Ww3xmzx5ypSmC2yX7/CYxAMtu1a5fTQ4qI2NJCcxExgpKZiBhByUxEjKBkJiJGUDITESMomYmIEZTMRMQIYds1sa+vz7ZgjikaZFvzJiYmUnHff/+9bYyTi8PZxfZs0W91dbVtDLvo+8cff6TimOJItrjZ4/HYxrCFqWxBMjN/tujUbrH0ZYN1mbkSu7idKTxljzlbxMoUJDPvH6YZgz+WjhQRCWNKZiJiBCUzETGCkpmIGEHJTESMoGQmIkZQMhMRIyiZiYgRlMxExAhhuwKAwVRws1XeP/zwAxXHVEDPnDmTGuvs2bNUHIOtBmcrvRlsC2WmipttOz3YXb6Gg60uZ14nuxrCSeyqCfbWhwx2n3V2dtrGMPs1mDth6sxMRIygZCYiRlAyExEjKJmJiBGUzETECEpmImIEJTMRMYKSmYgYQclMRIwQtisAmHsATJ061XacM2fO0NtjMFXLbA/63t5e25ienh5qLPZeAcw22fsmsPc6YLCrCZiKcLZKnelTD3DV/ez8W1tbqbiYmBjbGPa+D8xY7DFnV5Aw7w3mvRjMygqdmYmIEZTMRMQISmYiYgQlMxExgpKZiBhByUxEjKBkJiJGUDITESPc0EWzp06dsh2HLaBkiwGZ4lq21S8zFlvMyxY9RkRE2Maw+4wtaGSKNtm22UxxanJyMjVWU1MTFce8N9gCYvY4paWl2cacOHGCGosprmWPOfP+Abg27sxY7PaAYZyZHTx4EA8++CA8Hg8iIiKwd+/egN9bloXnn38eKSkpiImJQW5uLpV0RESuR9DJrL29HVlZWSgtLR3w95s3b8Ybb7yBbdu24fDhwxg3bhzy8vIcvamCiMjVgv6YmZ+fj/z8/AF/Z1kWtmzZgmeffRZLly4FALzzzjtISkrC3r178cgjj1zfbEVEBuHoBYC6ujo0NjYiNzfX/5zb7UZ2djYqKysH/Dvd3d3wer0BDxGRYDmazBobGwEASUlJAc8nJSX5f3e1kpISuN1u/yM1NdXJKYnITSLkpRnFxcVobW31P86dOxfqKYnIDcjRZHb5kvjVl7ybmpoGvVzucrkQFxcX8BARCZajySw9PR3JyckoKyvzP+f1enH48GHk5OQ4uSkRkQBBX81sa2vD6dOn/T/X1dXh2LFjSEhIQFpaGjZu3Ig//elPuO2225Ceno7nnnsOHo8Hy5Ytc3LeIiIBgk5mR44cwX333ef/uaioCACwcuVK7NixA08//TTa29uxdu1atLS04J577sH+/fsRHR0d1HYiIiJsq3+Zqmu2gv6BBx6g4vbv328bM3bsWGosZp+wbbOdXHXAVG8DfHV2Z2enbQxbgc6sFDh79iw1Frvqg9m3zGsEuNUQwKWTBDvse9vJtt/sMWf2rZOraYBhJLOFCxcOuYGIiAi8/PLLePnll4MdWkRk2EJ+NVNExAlKZiJiBCUzETGCkpmIGEHJTESMoGQmIkZQMhMRI4Rt22zLsmwL5phiQLZI8cCBA1QcU9zJFlDGx8fbxrDtpDMyMqi4K1dvDIYtxnSy0JLdJrP/o6KiqLHYOKZwmW2bzTYpZcdj3HLLLbYxzc3N1FhOttdmxmK3B+jMTEQMoWQmIkZQMhMRIyiZiYgRlMxExAhKZiJiBCUzETGCkpmIGEHJTESMELYrAJi22UxrXicrlgGupfT48eOpsXw+n20MWxl/4sQJKo6Zv5PtpIFLd+Cy4+RKB2aVA8Cv1GDeG+PGjaPGamlpoeKY1RUdHR3UWD/88INtDLsa4qfGvhcBnZmJiCGUzETECEpmImIEJTMRMYKSmYgYQclMRIygZCYiRlAyExEjKJmJiBHCdgVAZGSkbR905h4ATP/2y9tjMOOxfd4Z7D0M2JUCTmJXV0ydOtU2pqamhhrr5MmTtjHM+wJwdgVDW1sbNRZ7PJmVGmzVvpPvDXYsZt86eW8IQGdmImIIJTMRMYKSmYgYQclMRIygZCYiRlAyExEjKJmJiBGUzETECGFbNJuVlWVbVHfmzBnbcXp7e6ntscW1TrZQZgot2XbSLKbQkinYDEZdXZ1tTHt7OzUW00aZLbRkC6WZYxAdHU2NxbbqZtpms8eJKW5mC3DZQmNmnzHzZ7cHDOPM7ODBg3jwwQfh8XgQERGBvXv3Bvx+1apV/v79lx9LliwJdjMiIkEJOpm1t7cjKysLpaWlg8YsWbIEDQ0N/sd77713XZMUEbET9MfM/Px85OfnDxnjcrmQnJw87EmJiARrRC4AlJeXIzExERkZGVi/fj2am5sHje3u7obX6w14iIgEy/FktmTJErzzzjsoKyvDn//8Z1RUVCA/P3/QL2VLSkrgdrv9j9TUVKenJCI3AcevZj7yyCP+P8+ZMweZmZmYPn06ysvLsWjRomvii4uLUVRU5P/Z6/UqoYlI0Ea8zmzatGmYOHHioHeZdrlciIuLC3iIiARrxJPZ+fPn0dzcjJSUlJHelIjcxIL+mNnW1hZwllVXV4djx44hISEBCQkJeOmll1BQUIDk5GTU1tbi6aefxowZM5CXl+foxEVErhRhBVNii0tXKu+7775rnl+5ciW2bt2KZcuW4ejRo2hpaYHH48HixYvxxz/+EUlJSdT4Xq8XbrcbX375JWJjY4eMZabOfmzt6Oig4thW0QymvTZT8Q44W7XPtIkGgMmTJ1Nx9fX1tjFMxTvArcBg39LsMWew7wv2dTKrGJxsYc0ec7YlOfM6mfe2z+dDRkYGWltbbf8tB31mtnDhwiF3zoEDB4IdUkTkummhuYgYQclMRIygZCYiRlAyExEjKJmJiBGUzETECEpmImIEJTMRMULY3gNg7ty5ttXe58+ftx2HqbIH+AputgKa8VPfTwDgVgqwVeqnTp2i4ph9xt6rwcne+Cwn7zvAruhg9gfbt5+ZG7v/mfcsixkrmO3pzExEjKBkJiJGUDITESMomYmIEZTMRMQISmYiYgQlMxExgpKZiBghbItmv/jiC9u22a2trbbjxMTEUNtzsriWLdqMj4+3jWlvb6fGYtseMy2U2QJctmiTKXxki06dLCZl3xs9PT22MWzRNfs+i4yMtI1h24O73W7bmKFu1H0lJ4vLp0yZYhsTTFd/nZmJiBGUzETECEpmImIEJTMRMYKSmYgYQclMRIygZCYiRlAyExEjKJmJiBHCdgVARESEbeW4k5XlLGabbGtkZm5OtlkGgOnTp9vGnD59mhqLbWnMVLOzr7Ojo8M2hm1tzr43mBUdbGU8U40PcK+TrY5nVnSwK0jY1S3Mvq2trbWN8fl8yMzMpLapMzMRMYKSmYgYQclMRIygZCYiRlAyExEjKJmJiBGUzETECEpmImKEsC2adblctoV8TAtitoCSbbXMjOdkAShbjDlmDHcov/76a9uY6Ohoaqzu7m4qzsmxmOJOtgDU5/NRcUxxMFtAzLbNZoqgnWxhzWLf27Nnz7aNOXnypGPbA3RmJiKGCCqZlZSU4K677kJsbCwSExOxbNky1NTUBMR0dXWhsLAQEyZMwPjx41FQUICmpiZHJy0icrWgkllFRQUKCwtx6NAhfPzxx+jt7cXixYsD7iC0adMmfPjhh9i9ezcqKipw4cIFLF++3PGJi4hcKajvzPbv3x/w844dO5CYmIiqqiosWLAAra2tePvtt7Fz507cf//9AIDt27fj9ttvx6FDh3D33Xc7N3MRkStc13dml+9bmZCQAACoqqpCb28vcnNz/TGzZs1CWloaKisrBxyju7sbXq834CEiEqxhJ7P+/n5s3LgR8+fP91+5aGxsRFRU1DU3t01KSkJjY+OA45SUlMDtdvsfqampw52SiNzEhp3MCgsLUV1djV27dl3XBIqLi9Ha2up/nDt37rrGE5Gb07DqzDZs2ICPPvoIBw8exOTJk/3PJycno6enBy0tLQFnZ01NTUhOTh5wLKaeTETETlBnZpZlYcOGDdizZw8+/fRTpKenB/x+7ty5iIyMRFlZmf+5mpoa1NfXIycnx5kZi4gMIKgzs8LCQuzcuRP79u1DbGys/3swt9uNmJgYuN1urF69GkVFRUhISEBcXByefPJJ5OTkBH0lMysry7aq+uzZs7bjsK2R2TimVTFbjd/T02Mbw1aWsxX0zPzZFtxsC+XOzk7bGLaanZk/uy/YfcscT7bKPjY2lopzcp8xx4mttGdbdZ84cYKKc1JQyWzr1q0AgIULFwY8v337dqxatQoA8Prrr2PUqFEoKChAd3c38vLy8NZbbzkyWRGRwQSVzJisHB0djdLSUpSWlg57UiIiwdLaTBExgpKZiBhByUxEjKBkJiJGUDITESMomYmIEZTMRMQIYXsPgMOHD9tWSyclJdmO8+2331LbY6rxAa7qmqneBnBNd5GBXNn4cihs336mVpDtUx8ZGUnFMZX27AoMptKevZ/DuHHjqDjmvcGu+mhpaaHimPXKbDW+2+22jWlubqbGYlcdOHXM2fcFoDMzETGEkpmIGEHJTESMoGQmIkZQMhMRIyiZiYgRlMxExAhKZiJihLAtmo2KiqKLH4fCtoBmCxCZObEFuMzc2NbUbKtopriTbaHMYvatky2sncYU6jrZ9hvg37cMZp+x82eLs5n5M/uVff8DOjMTEUMomYmIEZTMRMQISmYiYgQlMxExgpKZiBhByUxEjKBkJiJGUDITESOE7QqA/v5+2+rf7777znactrY2antMm2KAq+5nq6SZ9tozZsygxjp9+jQVx7QhZtosA8APP/xAxTEV6GzFu5MrMNg4BtvemV3BwFTHsys1mpqabGOmTp3q2FgAV7nPHMtgVgHpzExEjKBkJiJGUDITESMomYmIEZTMRMQISmYiYgQlMxExgpKZiBhByUxEjBC2KwBcLpdtVT5T3c/2EGcr0Jle6WyVN1PB/c0331Bjsa+T6bXf2tpKjcWudGD7+zOYyni2zz57nJh9O3v2bGqs6upqKo55b7CvMy4uzjamoaGBGoutyGf2GXPfCvbeFkCQZ2YlJSW46667EBsbi8TERCxbtgw1NTUBMQsXLkRERETAY926dcFsRkQkaEEls4qKChQWFuLQoUP4+OOP0dvbi8WLF6O9vT0gbs2aNWhoaPA/Nm/e7OikRUSuFtTHzP379wf8vGPHDiQmJqKqqgoLFizwPz927FgkJyc7M0MREcJ1XQC4/N1KQkJCwPPvvvsuJk6ciNmzZ6O4uBgdHR2DjtHd3Q2v1xvwEBEJ1rAvAPT392Pjxo2YP39+wJefjz32GKZMmQKPx4Pjx4/jmWeeQU1NDT744IMBxykpKcFLL7003GmIiAC4jmRWWFiI6upqfP755wHPr1271v/nOXPmICUlBYsWLUJtbS2mT59+zTjFxcUoKiry/+z1epGamjrcaYnITWpYyWzDhg346KOPcPDgQUyePHnI2OzsbACXmgcOlMyYEgwRETtBJTPLsvDkk09iz549KC8vR3p6uu3fOXbsGAAgJSVlWBMUEWEElcwKCwuxc+dO7Nu3D7GxsWhsbARwqc1yTEwMamtrsXPnTvzqV7/ChAkTcPz4cWzatAkLFixAZmZmUBPr6elxpK0xW7DJFp0yhZY+n48aiylmHOriyZXY1zlz5kzbmBMnTlBjsW2bIyMjbWPYAlDmdbL7gpkXwLXX/uqrr6ixmKJrgGvDze5/5n124cIFaiz2OLH/npwUVDLbunUrgEuFsVfavn07Vq1ahaioKHzyySfYsmUL2tvbkZqaioKCAjz77LOOTVhEZCBBf8wcSmpqKioqKq5rQiIiw6GF5iJiBCUzETGCkpmIGEHJTESMoGQmIkZQMhMRIyiZiYgRwrZtdl9fn20VNFPpza77vPXWW6m4uro6Ko7BVPc72Q4b4Obf1dVFjcVUqbPY+TMV9Gw7b6YFN8C1imaPE7uqJT4+3jampaWFGuu7776zjWHnz+4zZqUM828zmFVAOjMTESMomYmIEZTMRMQISmYiYgQlMxExgpKZiBhByUxEjKBkJiJGCNui2ejoaNvix97eXttxOjs7qe3V1tZScYwrb703lJqaGtsYts0yW1zIFEey7aTZolkmzsniYHasmJgYKo4pbna6UJdpvc62zWaMGzeOimMKiAHgv//9r20McyxVNCsiNx0lMxExgpKZiBhByUxEjKBkJiJGUDITESMomYmIEZTMRMQISmYiYoSwXQHQ2dlp23rXsizbcdhqdmYsgKvIr66upsZiqqnZFtaxsbFUnMfjsY1hV0Owra4ZTJtlgKvuZ1uls6tDGGylOrvPmOp+djUBMxazygHgX+fYsWNtY5j5s/9+AZ2ZiYghlMxExAhKZiJiBCUzETGCkpmIGEHJTESMoGQmIkZQMhMRIyiZiYgRwnYFwNy5c22rpc+cOWM7DluxzPZwZ+47wFagd3d3U3EMtoL766+/to1hq9TZewAw2HsdMFXj7PydXMHAzp/t28+uSGEwq0jGjx9PjcWu1GhtbbWNYfZ/MO+xoM7Mtm7diszMTMTFxSEuLg45OTn4+9//7v99V1cXCgsLMWHCBIwfPx4FBQVoamoKZhMiIsMSVDKbPHkyXnnlFVRVVeHIkSO4//77sXTpUvznP/8BAGzatAkffvghdu/ejYqKCly4cAHLly8fkYmLiFwpwrrO89mEhAS8+uqrePjhhzFp0iTs3LkTDz/8MADg5MmTuP3221FZWYm7776bGs/r9cLtdmPMmDE37MdM9qMEcwrNHh729mpMHPtRIlw/ZgazOJnBHAP2mDv5MZN9bzNjsbea+6k/Zvp8PmRmZqK1tRVxcXFDxg77AkBfXx927dqF9vZ25OTkoKqqCr29vcjNzfXHzJo1C2lpaaisrBx0nO7ubni93oCHiEiwgk5mX375JcaPHw+Xy4V169Zhz549uOOOO9DY2IioqCjEx8cHxCclJaGxsXHQ8UpKSuB2u/2P1NTUoF+EiEjQySwjIwPHjh3D4cOHsX79eqxcuRInTpwY9gSKi4vR2trqf5w7d27YY4nIzSvo0oyoqCjMmDEDwKXyiX/961/4y1/+ghUrVqCnpwctLS0BZ2dNTU1ITk4edDyXy0WXMoiIDOa6i2b7+/vR3d2NuXPnIjIyEmVlZf7f1dTUoL6+Hjk5Ode7GRGRIQV1ZlZcXIz8/HykpaXB5/Nh586dKC8vx4EDB+B2u7F69WoUFRUhISEBcXFxePLJJ5GTk0NfybzS8ePHbVtBM1dzYmJiqO21t7dTccxVH7YdM3Nlkb3Kx17NZPYHW8zLzo25asW0WQacbXXtZNHs9OnTqTj2KxnmfcZeTWYKYtmia/bqOnNFmakMCKbYIqhkdvHiRfz6179GQ0MD3G43MjMzceDAATzwwAMAgNdffx2jRo1CQUEBuru7kZeXh7feeiuYTYiIDEtQyeztt98e8vfR0dEoLS1FaWnpdU1KRCRYWmguIkZQMhMRIyiZiYgRlMxExAhKZiJiBCUzETFC2HWavVwk19bWZhvLtINhYgC+aJYpTg3nollmf7BFs052dGULQMO1aJYt7vT5fFQcczzZ9ywzN3a//tRFs5fzALPd6+5n5rTz58+rc4aIBDh37hwmT548ZEzYJbP+/n5cuHABsbGx/v85vV4vUlNTce7cOdsGbeFI8w+9G/013KzztywLPp8PHo/H9lNK2H3MHDVq1KAZ+PK9B25Umn/o3eiv4Wacv9vtpuJ0AUBEjKBkJiJGuCGSmcvlwgsvvHDDNnHU/EPvRn8Nmr+9sLsAICIyHDfEmZmIiB0lMxExgpKZiBhByUxEjHBDJLPS0lJMnToV0dHRyM7OxhdffBHqKVFefPFFREREBDxmzZoV6mkN6uDBg3jwwQfh8XgQERGBvXv3Bvzesiw8//zzSElJQUxMDHJzc3Hq1KnQTHYAdvNftWrVNcdjyZIloZnsAEpKSnDXXXchNjYWiYmJWLZsGWpqagJiurq6UFhYiAkTJmD8+PEoKChAU1NTiGYciJn/woULrzkG69atc2T7YZ/M3n//fRQVFeGFF17Av//9b2RlZSEvLw8XL14M9dQod955JxoaGvyPzz//PNRTGlR7ezuysrIGvYfD5s2b8cYbb2Dbtm04fPgwxo0bh7y8PHR1df3EMx2Y3fwBYMmSJQHH47333vsJZzi0iooKFBYW4tChQ/j444/R29uLxYsXBywo37RpEz788EPs3r0bFRUVuHDhApYvXx7CWf8PM38AWLNmTcAx2Lx5szMTsMLcvHnzrMLCQv/PfX19lsfjsUpKSkI4K84LL7xgZWVlhXoawwLA2rNnj//n/v5+Kzk52Xr11Vf9z7W0tFgul8t67733QjDDoV09f8uyrJUrV1pLly4NyXyG4+LFixYAq6KiwrKsS/s7MjLS2r17tz/mq6++sgBYlZWVoZrmoK6ev2VZ1i9/+Uvrt7/97YhsL6zPzHp6elBVVYXc3Fz/c6NGjUJubi4qKytDODPeqVOn4PF4MG3aNDz++OOor68P9ZSGpa6uDo2NjQHHwu12Izs7+4Y5FgBQXl6OxMREZGRkYP369Whubg71lAbV2toKAEhISAAAVFVVobe3N+AYzJo1C2lpaWF5DK6e/2XvvvsuJk6ciNmzZ6O4uJi+Z6edsFtofqXvv/8efX19SEpKCng+KSkJJ0+eDNGseNnZ2dixYwcyMjLQ0NCAl156Cffeey+qq6ttb3AcbhobGwFgwGNx+XfhbsmSJVi+fDnS09NRW1uLP/zhD8jPz0dlZSVGjx4d6ukF6O/vx8aNGzF//nzMnj0bwKVjEBUVhfj4+IDYcDwGA80fAB577DFMmTIFHo8Hx48fxzPPPIOamhp88MEH173NsE5mN7r8/Hz/nzMzM5GdnY0pU6bgb3/7G1avXh3Cmd2cHnnkEf+f58yZg8zMTEyfPh3l5eVYtGhRCGd2rcLCQlRXV4f1d6xDGWz+a9eu9f95zpw5SElJwaJFi1BbW0vfFX4wYf0xc+LEiRg9evQ1V2uampqQnJwcolkNX3x8PGbOnInTp0+HeipBu7y/TTkWADBt2jRMnDgx7I7Hhg0b8NFHH+Gzzz4LaIeVnJyMnp4etLS0BMSH2zEYbP4Dyc7OBgBHjkFYJ7OoqCjMnTsXZWVl/uf6+/tRVlaGnJycEM5seNra2lBbW4uUlJRQTyVo6enpSE5ODjgWXq8Xhw8fviGPBXCpq3Fzc3PYHA/LsrBhwwbs2bMHn376KdLT0wN+P3fuXERGRgYcg5qaGtTX14fFMbCb/0COHTsGAM4cgxG5rOCgXbt2WS6Xy9qxY4d14sQJa+3atVZ8fLzV2NgY6qnZ+t3vfmeVl5dbdXV11j/+8Q8rNzfXmjhxonXx4sVQT21APp/POnr0qHX06FELgPXaa69ZR48etc6ePWtZlmW98sorVnx8vLVv3z7r+PHj1tKlS6309HSrs7MzxDO/ZKj5+3w+66mnnrIqKyuturo665NPPrF+/vOfW7fddpvV1dUV6qlblmVZ69evt9xut1VeXm41NDT4Hx0dHf6YdevWWWlpadann35qHTlyxMrJybFycnJCOOv/sZv/6dOnrZdfftk6cuSIVVdXZ+3bt8+aNm2atWDBAke2H/bJzLIs680337TS0tKsqKgoa968edahQ4dCPSXKihUrrJSUFCsqKsq69dZbrRUrVlinT58O9bQG9dlnn1kArnmsXLnSsqxL5RnPPfeclZSUZLlcLmvRokVWTU1NaCd9haHm39HRYS1evNiaNGmSFRkZaU2ZMsVas2ZNWP2nONDcAVjbt2/3x3R2dlq/+c1vrFtuucUaO3as9dBDD1kNDQ2hm/QV7OZfX19vLViwwEpISLBcLpc1Y8YM6/e//73V2trqyPbVAkhEjBDW35mJiLCUzETECEpmImIEJTMRMYKSmYgYQclMRIygZCYiRlAyExEjKJmJiBGUzETECEpmImIEJTMRMcL/AY4nXd43XnU8AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(dlogits.detach(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max diff: tensor(4.7684e-07, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3: backprop through batchnorm but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the output of batchnorm,\n",
    "# take the derivative w.r.t. its input, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "# bndiff = hprebn - bnmeani\n",
    "# bndiff2 = bndiff**2\n",
    "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "# bnraw = bndiff * bnvar_inv\n",
    "# hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# now:\n",
    "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n",
    "print('max diff:', (hpreact_fast - hpreact).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "# before we had:\n",
    "# dbnraw = bngain * dhpreact\n",
    "# dbndiff = bnvar_inv * dbnraw\n",
    "# dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "# dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "# dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "# dbndiff += (2*bndiff) * dbndiff2\n",
    "# dhprebn = dbndiff.clone()\n",
    "# dbnmeani = (-dbndiff).sum(0)\n",
    "# dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
    "\n",
    "# calculate dhprebn given dhpreact (i.e. backprop through the batchnorm)\n",
    "# (you'll also need to use some of the variables from the forward pass up above)\n",
    "\n",
    "dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "\n",
    "cmp('hprebn', dhprebn, hprebn) # I can only get approximate to be true, my maxdiff is 9e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([64]))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhprebn.shape, bngain.shape, bnvar_inv.shape, dbnraw.shape, dbnraw.sum(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12297\n",
      "      0/ 200000: 3.8046\n",
      "  10000/ 200000: 2.1960\n",
      "  20000/ 200000: 2.3583\n",
      "  30000/ 200000: 2.4452\n",
      "  40000/ 200000: 1.9793\n",
      "  50000/ 200000: 2.3618\n",
      "  60000/ 200000: 2.3361\n",
      "  70000/ 200000: 2.0650\n",
      "  80000/ 200000: 2.3156\n",
      "  90000/ 200000: 2.1307\n",
      " 100000/ 200000: 1.9521\n",
      " 110000/ 200000: 2.3037\n",
      " 120000/ 200000: 1.9739\n",
      " 130000/ 200000: 2.4065\n",
      " 140000/ 200000: 2.2955\n",
      " 150000/ 200000: 2.2060\n",
      " 160000/ 200000: 1.9223\n",
      " 170000/ 200000: 1.8243\n",
      " 180000/ 200000: 1.9269\n",
      " 190000/ 200000: 1.8405\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: putting it all together!\n",
    "# Train the MLP neural net with your own backward pass\n",
    "\n",
    "# init\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True\n",
    "\n",
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "n = batch_size # convenience\n",
    "lossi = []\n",
    "\n",
    "# use this context manager for efficiency once your backward pass is written (TODO)\n",
    "with torch.no_grad():\n",
    "\n",
    "  # kick off optimization\n",
    "  for i in range(max_steps):\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # embed the characters into vectors\n",
    "    embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "    # Linear layer\n",
    "    hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "    # BatchNorm layer\n",
    "    # -------------------------------------------------------------\n",
    "    bnmean = hprebn.mean(0, keepdim=True)\n",
    "    bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "    bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "    bnraw = (hprebn - bnmean) * bnvar_inv\n",
    "    hpreact = bngain * bnraw + bnbias\n",
    "    # -------------------------------------------------------------\n",
    "    # Non-linearity\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "      p.grad = None\n",
    "    #loss.backward() # use this for correctness comparisons, delete it later!\n",
    "\n",
    "    # manual backprop! #swole_doge_meme\n",
    "    # -----------------\n",
    "    dlogits = F.softmax(logits, 1)\n",
    "    dlogits[range(n), Yb] -= 1\n",
    "    dlogits /= n\n",
    "    # 2nd layer backprop\n",
    "    dh = dlogits @ W2.T\n",
    "    dW2 = h.T @ dlogits\n",
    "    db2 = dlogits.sum(0)\n",
    "    # tanh\n",
    "    dhpreact = (1.0 - h**2) * dh\n",
    "    # batchnorm backprop\n",
    "    dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "    dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "    dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "    # 1st layer\n",
    "    dembcat = dhprebn @ W1.T\n",
    "    dW1 = embcat.T @ dhprebn\n",
    "    db1 = dhprebn.sum(0)\n",
    "    # embedding\n",
    "    demb = dembcat.view(emb.shape)\n",
    "    dC = torch.zeros_like(C)\n",
    "    for k in range(Xb.shape[0]):\n",
    "      for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k,j]\n",
    "        dC[ix] += demb[k,j]\n",
    "    grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
    "    # -----------------\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
    "    for p, grad in zip(parameters, grads):\n",
    "      #p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
    "      p.data += -lr * grad # new way of swole doge TODO: enable\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0: # print every once in a while\n",
    "      print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.log10().item())\n",
    "\n",
    "  #   if i >= 100: # TODO: delete early breaking when you're ready to train the full net\n",
    "  #     break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
