{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-25T23:58:16.091187Z",
     "start_time": "2024-02-25T23:58:14.408176Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T23:58:16.099423Z",
     "start_time": "2024-02-25T23:58:16.091176Z"
    }
   },
   "id": "794e8ec2fead3bd4",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "32033"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T23:58:18.424933Z",
     "start_time": "2024-02-25T23:58:18.405065Z"
    }
   },
   "id": "c5f9e406c5dba1e6",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "N = torch.zeros((27,27))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T23:58:18.980387Z",
     "start_time": "2024-02-25T23:58:18.971354Z"
    }
   },
   "id": "832e0fbd917cd9a0",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "for w in words:\n",
    "  chs = ['.'] + list(w) + ['.']\n",
    "  for ch1, ch2 in zip(chs, chs[1:]):\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    N[ix1, ix2] += 1\n",
    "# build the dataset\n",
    "\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "X, Y = [], []\n",
    "\n",
    "for w in words[:1]:\n",
    "  context = [0] * block_size\n",
    "  for ch in (w + '.'):\n",
    "    X.append(context)\n",
    "    ix = stoi[ch]\n",
    "    Y.append(ix)\n",
    "    print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "    context = context[1:] + [ix]\n",
    "# for w in words:\n",
    "#   #print(w)\n",
    "#   context = [0] * block_size # duplicate [0] to [0,0,0]\n",
    "#   for ch in w + '.':\n",
    "#     ix = stoi[ch]\n",
    "#     X.append(context)\n",
    "#     Y.append(ix)\n",
    "#     print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "#     context = context[1:] + [ix] # crop and append\n",
    "#     # context will always fall behind one bit from true label\n",
    "  \n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T00:30:29.994504Z",
     "start_time": "2024-02-26T00:30:29.795236Z"
    }
   },
   "id": "5826e7e2d314a5b5",
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0,  0,  0],\n        [ 0,  0,  5],\n        [ 0,  5, 13],\n        [ 5, 13, 13],\n        [13, 13,  1]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T00:03:05.332067Z",
     "start_time": "2024-02-26T00:03:05.324301Z"
    }
   },
   "id": "5fc7b908adf29845",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 5, 13, 13,  1,  0])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T00:03:07.857529Z",
     "start_time": "2024-02-26T00:03:07.853117Z"
    }
   },
   "id": "cde0ca66ae54840a",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([5, 3]), torch.int64, torch.Size([5]), torch.int64)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T00:03:13.320026Z",
     "start_time": "2024-02-26T00:03:13.311286Z"
    }
   },
   "id": "50abc831062b4d50",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.8149, -1.4727],\n        [-1.6462, -1.4466],\n        [ 0.0954,  0.2717],\n        [ 0.4230, -0.4369],\n        [-1.1684,  2.0900],\n        [ 0.6220,  1.0828],\n        [-0.1982, -0.0445],\n        [ 1.3953,  1.0711],\n        [-1.1981, -1.1842],\n        [ 0.3029,  1.2056],\n        [ 0.8761, -1.2525],\n        [ 0.0366,  1.8045],\n        [-0.7391,  0.0728],\n        [-1.1231,  0.1798],\n        [-1.4057,  0.8786],\n        [ 1.2651,  1.3113],\n        [ 0.5063,  1.7261],\n        [-1.1865,  0.8545],\n        [ 0.6775, -0.4491],\n        [-1.2347, -0.5361],\n        [ 0.2071,  0.8200],\n        [ 0.7417,  0.4729],\n        [ 0.6101, -0.8640],\n        [-1.7173, -1.2424],\n        [ 0.9097,  0.5655],\n        [ 1.3417,  1.5396],\n        [ 1.6055,  2.4652]])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A layer of two neurons\n",
    "C = torch.randn((27, 2))\n",
    "C"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T00:06:47.932874Z",
     "start_time": "2024-02-26T00:06:47.925197Z"
    }
   },
   "id": "b018e081a7fb1df1",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[-0.8149, -1.4727],\n         [-0.8149, -1.4727],\n         [-0.8149, -1.4727]],\n\n        [[-0.8149, -1.4727],\n         [-0.8149, -1.4727],\n         [ 0.6220,  1.0828]],\n\n        [[-0.8149, -1.4727],\n         [ 0.6220,  1.0828],\n         [-1.1231,  0.1798]],\n\n        [[ 0.6220,  1.0828],\n         [-1.1231,  0.1798],\n         [-1.1231,  0.1798]],\n\n        [[-1.1231,  0.1798],\n         [-1.1231,  0.1798],\n         [-1.6462, -1.4466]]])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This operation is performing indexing into C using X as the index tensor. Here's what happens step by step:\n",
    "\n",
    "    Indexing with X: For each row in X, the values are treated as indices to fetch rows from C. Since X has 3 columns, each row of X will select 3 rows from C. The result is that for every row in X, you get a corresponding set of 3 embedding vectors from C.\n",
    "\n",
    "    Shape of the Result (emb): Given that each row in X leads to selecting 3 embedding vectors from C, and each embedding vector has a dimensionality of 2 (since C has shape [27, 2]), the resulting tensor emb will have a shape that reflects the combination of these dimensions. Specifically, the shape of emb will be [228146, 3, 2]. This means there are 228146 groups of embeddings, each group containing 3 embeddings, and each embedding having 2 dimensions.\n",
    "'''\n",
    "emb = C[X] # ???? Why ?\n",
    "emb.shape\n",
    "C[X]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T00:08:06.734475Z",
     "start_time": "2024-02-26T00:08:06.729627Z"
    }
   },
   "id": "d4c4d03a2ffdb22a",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# There are 100 neurons, each accepts a 6-D input sample\n",
    "\n",
    "W1 = torch.randn((6, 100))\n",
    "b1 = torch.randn(100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T00:08:45.344383Z",
     "start_time": "2024-02-26T00:08:45.337204Z"
    }
   },
   "id": "8c0f5fa48359d727",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# emb.view(-1, 6): == there are 228146 samples, each sample has 6 dimensions.\n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T00:08:46.250865Z",
     "start_time": "2024-02-26T00:08:46.246570Z"
    }
   },
   "id": "6eaa5fb2f33647e5",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-1.0000,  0.9985, -0.9994,  0.9996, -0.9725,  0.0023,  1.0000, -0.9915,\n         -0.9717, -1.0000,  0.9971,  1.0000,  0.6101, -0.5457,  0.1668,  0.9691,\n         -0.8079,  0.9292,  1.0000, -1.0000, -0.5810,  0.9999,  1.0000,  0.2651,\n         -0.8415, -0.3284,  0.9265, -0.9991, -0.9612,  0.9733, -1.0000, -0.7332,\n         -0.9998, -0.9999, -0.8929, -0.0817,  0.9984, -0.5807, -0.9764, -0.9015,\n         -0.1723,  0.9993, -0.7332, -1.0000, -0.9901,  0.9899,  0.2998, -0.9971,\n          0.1915, -0.9358,  1.0000, -0.9923, -0.9835,  0.4891,  0.9652,  0.9944,\n          1.0000,  1.0000,  0.1442, -0.5955, -0.9989, -0.9839,  0.9720,  0.7074,\n         -0.2623, -0.6433, -0.9990, -0.1673,  0.8817, -0.9999,  0.3646, -0.9703,\n          0.9993, -0.3617,  0.8942, -0.9415,  0.8816, -0.9973,  0.9979, -0.9959,\n          0.3781,  0.9011,  1.0000,  0.9994,  0.9962,  0.6486,  0.9954, -1.0000,\n         -1.0000, -1.0000, -0.9944,  0.9993, -0.8148, -0.5515, -0.9925,  0.7764,\n          0.6764,  0.8880,  0.9994,  0.9761],\n        [-1.0000,  0.9980,  0.4207,  0.9996, -0.7858, -0.5083,  1.0000, -0.9994,\n         -0.9988, -0.9999,  0.8746, -0.1768, -0.5829, -0.9729,  0.9750,  0.9677,\n          0.8679, -0.8337, -0.7343, -0.9995, -0.9991,  0.9043,  0.9998,  0.9605,\n         -0.9832,  0.3466, -0.9996, -0.9979, -0.4643, -0.9988, -1.0000, -0.9945,\n         -0.9978,  0.0552, -0.5265,  0.9999,  0.8803,  0.9248,  0.9398,  0.9976,\n          0.9007,  0.9627, -0.7220, -0.9995,  0.9995, -0.4222,  0.9997, -0.9886,\n         -0.6544, -0.9775,  0.9994, -0.9989, -0.3644,  0.5814,  0.9900, -0.9050,\n         -0.5170,  0.9916, -0.9098,  0.7627, -1.0000, -1.0000,  0.9824, -0.9998,\n          0.2334,  0.1968, -0.9931,  0.9881, -0.9830, -0.7944, -0.9995,  0.1108,\n          0.9999,  0.9942, -0.4847,  0.9863,  0.9938,  0.9924,  0.9999, -0.8959,\n         -0.9999,  0.5445,  0.9998,  0.9980, -0.8594,  0.9827,  0.9896, -0.9823,\n         -0.5249, -0.9639, -0.9992,  0.9998,  0.3753, -0.8263, -0.9831,  0.9904,\n          0.3866,  0.6032,  0.9135,  0.9370],\n        [ 0.8553,  0.9131, -0.8376, -0.1977,  0.9429,  0.8902, -0.5561,  0.4629,\n         -0.9999, -0.9069,  0.9187,  0.7966,  0.9967,  0.9958,  0.5962,  1.0000,\n         -0.1335,  0.9986,  0.9829, -0.9579,  0.0806,  0.9965,  0.9274,  0.8357,\n          0.6463,  0.9761,  0.9997, -0.3278, -0.9994, -0.9740, -1.0000, -0.9631,\n         -0.6711, -0.9984, -0.9943,  0.9806,  0.9865, -0.7550, -0.0055,  0.8098,\n          0.0755, -0.6492, -0.5555, -0.3241, -0.9953, -0.9406,  0.9565, -0.3616,\n         -0.9256, -0.4276,  0.9910, -0.9262,  0.9921, -0.7206,  0.9999,  0.9906,\n          0.9915,  0.9977, -0.5590,  0.9817, -0.9963, -1.0000,  0.9123, -0.9999,\n         -0.9977, -0.6420, -0.9996,  0.7898,  0.9999, -1.0000,  0.9587, -0.9474,\n          0.9936,  0.7840, -0.9944,  0.3749, -0.3644, -0.6747,  0.3610,  0.9994,\n          0.8916,  0.1868,  0.4810,  0.3886,  0.1073,  0.9662,  0.9066, -0.9987,\n         -0.2387, -0.9724,  0.7082, -0.9890,  0.7413, -0.9242,  0.9962,  0.9746,\n         -0.9999, -0.9989, -0.9861,  0.9991],\n        [ 0.9463, -0.1202, -0.9599,  0.6433, -0.9940,  0.6454,  0.9981,  0.8705,\n          0.9631,  0.4420, -0.5487, -0.9733, -0.9764, -0.9857, -0.1743, -0.9494,\n         -0.9953, -0.9483,  0.2770,  0.9464, -0.6219, -0.9512,  0.3009, -0.7277,\n          0.8656,  0.9999,  0.9927,  0.9707, -0.8053,  0.7658,  0.4818,  0.0689,\n         -0.9983, -0.0738, -0.9999,  0.9985, -0.9565, -0.9459, -0.3713, -0.9153,\n         -0.2188,  0.9930,  0.9996, -0.5334, -0.9141,  0.9379, -0.9999,  0.9998,\n          0.9992,  0.5068,  0.9788, -0.2632, -0.8987, -0.9757,  0.5147,  0.9977,\n         -0.9130, -0.9342,  0.9997, -0.8958, -0.1581, -0.9994,  0.0791,  0.9986,\n         -0.9983,  0.9557,  0.9685,  0.8548,  0.6596,  0.9476,  0.3979, -0.9954,\n          0.9593,  0.3468,  0.9576, -0.8690, -0.8233,  0.7154, -0.0496, -0.4639,\n          0.1171,  0.6169, -0.9725, -0.6149,  0.3214,  0.9349, -0.2810, -0.6775,\n         -0.9979, -0.8806, -0.9708,  0.9988,  0.4574,  0.9252, -0.9986,  0.9879,\n          0.9374,  0.9473,  0.9889, -0.1165],\n        [-0.9821,  0.0572, -0.9969,  0.9845, -0.9995,  0.9924,  0.9996,  0.9832,\n         -0.4956, -0.9999,  0.9245,  0.9997,  0.0029, -0.9888,  0.5975,  0.7778,\n         -0.9988, -0.7960,  0.9999, -0.8527, -0.1957,  0.9995,  0.8557,  0.5661,\n         -0.1046,  0.9165,  1.0000, -0.6368, -0.9987,  0.9841, -0.9933,  0.6457,\n         -1.0000, -1.0000, -1.0000,  0.0782,  0.9479, -0.9015, -0.9342, -0.9257,\n         -0.9886,  0.9775,  0.9981, -0.9997, -1.0000,  0.9976, -0.9988,  0.9157,\n          0.9733,  0.5095,  1.0000, -0.5476, -0.9611, -0.9450,  0.9866,  0.9997,\n          1.0000,  0.9779,  0.9998, -0.9925, -0.5358, -0.9995, -0.1641,  0.9917,\n         -0.9999,  0.5680, -0.7675, -0.9019,  0.9998, -0.9996,  0.9765, -0.9993,\n          0.9442, -0.9085,  0.9624, -0.9900, -0.2865, -0.9989,  0.6517,  0.4121,\n          0.9990,  0.7947,  0.9999, -0.5863,  0.9626,  0.0456,  0.3120, -0.9996,\n         -1.0000, -1.0000, -0.9533,  0.0835,  0.7990,  0.9645, -0.6896,  0.9918,\n          0.9164,  0.9722,  0.9333,  0.7843]])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T00:08:49.438707Z",
     "start_time": "2024-02-26T00:08:49.431178Z"
    }
   },
   "id": "936bf7b440f8d5f7",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([5, 100])"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T00:08:55.016631Z",
     "start_time": "2024-02-26T00:08:55.013676Z"
    }
   },
   "id": "228187fd3efa2604",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# There are 27 neurons, each accepts a 100-D input sample\n",
    "W2 = torch.randn((100, 27))\n",
    "b2 = torch.randn(27)\n",
    "logits = h @ W2 + b2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T00:10:27.889476Z",
     "start_time": "2024-02-26T00:10:27.881140Z"
    }
   },
   "id": "254bb1fc7d7c56bb",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "logits = h @ W2 + b2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T00:10:29.903663Z",
     "start_time": "2024-02-26T00:10:29.898297Z"
    }
   },
   "id": "9e61a39c63fb331f",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([5, 27])"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (5,27)\n",
    "logits.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T00:10:54.654272Z",
     "start_time": "2024-02-26T00:10:54.647964Z"
    }
   },
   "id": "a7978bb2ad78afc3",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "counts = logits.exp()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T00:11:02.599180Z",
     "start_time": "2024-02-26T00:11:02.593331Z"
    }
   },
   "id": "507a34cc2f439a1",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# (5,27)\n",
    "# Output the predictions for five samples.\n",
    "# Each prediction is a 27-D row vector, each element of the vector represents the prob of the next char represented by the element.\n",
    "# For instance, if prob[0, 1] == 0.1, it means that for the first sample (a character, in our situation it's 'e'), the probability of the next char being 'a' (since it's index is 1) is 0.1.\n",
    "prob = counts / counts.sum(1, keepdims=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T00:11:17.934281Z",
     "start_time": "2024-02-26T00:11:17.923024Z"
    }
   },
   "id": "7f8a1f1fbe665689",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[8.1966e-12, 3.2003e-13, 5.8466e-11, 7.3979e-07, 1.5233e-14, 6.1835e-15,\n         2.5206e-12, 8.0280e-09, 7.7497e-13, 5.3522e-14, 5.9385e-08, 9.9926e-01,\n         9.1213e-10, 2.3907e-11, 4.2429e-16, 3.3384e-11, 2.2160e-13, 6.3803e-08,\n         1.0248e-09, 1.9334e-10, 1.7824e-07, 4.7604e-17, 9.2861e-20, 2.0522e-10,\n         2.2402e-12, 1.2692e-11, 7.4164e-04],\n        [1.9490e-11, 1.6314e-09, 4.7649e-07, 2.7038e-10, 2.0440e-13, 8.7033e-12,\n         6.1506e-12, 1.1086e-09, 2.8329e-17, 1.3611e-10, 9.1783e-09, 7.5510e-08,\n         1.4883e-18, 1.6413e-07, 1.6145e-08, 6.9429e-15, 9.1780e-17, 2.5108e-12,\n         1.3492e-13, 7.6261e-09, 1.1037e-06, 1.4717e-17, 3.5639e-17, 1.1905e-08,\n         1.4942e-05, 1.0704e-05, 9.9997e-01],\n        [2.3013e-07, 2.3073e-05, 4.3382e-06, 1.2428e-05, 1.9314e-10, 1.0398e-11,\n         9.3780e-05, 1.8331e-03, 5.4539e-07, 1.3202e-08, 7.2372e-04, 1.8942e-05,\n         1.4739e-10, 1.5229e-09, 5.0274e-06, 4.4397e-06, 1.4895e-14, 8.8519e-03,\n         1.7718e-07, 9.8651e-01, 1.7681e-03, 3.3314e-09, 7.9277e-18, 1.4571e-04,\n         3.7011e-09, 7.4738e-07, 2.2608e-12],\n        [3.2744e-08, 8.5233e-16, 1.1610e-09, 6.9851e-08, 7.1435e-11, 9.4075e-08,\n         3.1784e-10, 2.3659e-03, 1.2725e-05, 3.4364e-11, 3.4001e-07, 7.2316e-01,\n         1.5824e-03, 2.4727e-05, 7.0496e-09, 7.7834e-08, 1.7811e-08, 4.8449e-09,\n         1.4332e-09, 2.1601e-15, 1.0022e-06, 4.4992e-11, 6.0287e-09, 1.8564e-07,\n         6.8595e-08, 1.4152e-13, 2.7285e-01],\n        [1.2273e-12, 1.7335e-15, 3.6693e-13, 5.1274e-08, 7.8823e-15, 6.6892e-10,\n         9.3035e-14, 2.2820e-09, 7.1039e-14, 6.5812e-17, 3.3751e-10, 1.0000e+00,\n         2.0827e-06, 1.3251e-13, 3.3349e-14, 3.0452e-15, 3.2926e-13, 8.2635e-07,\n         1.6135e-10, 3.3128e-12, 5.4978e-10, 2.3919e-15, 1.1518e-15, 1.5529e-14,\n         8.4551e-16, 1.9158e-15, 3.1242e-09]])"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T00:14:17.390952Z",
     "start_time": "2024-02-26T00:14:17.385892Z"
    }
   },
   "id": "7697de0f506fb927",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([5, 27])"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T00:11:33.882903Z",
     "start_time": "2024-02-26T00:11:33.874380Z"
    }
   },
   "id": "f287984b4be9f7b4",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(26.1534)"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prob[torch.arange(5), Y] == prob[[0,1,2,3,4], Y]. Y is the ground truth, representing the label of the next token.\n",
    "# Suppose Y == [ 5, 13, 13,  1,  0]. Then:\n",
    "# 1. prob[0,5] means the prob of the next token of the first sample being 5 (means 'e'). Or it's the accuracy of the model for the first sample.\n",
    "# 2. prob[1,13] means the prob of the next token of the first sample being 13 (means 'm'). Or it's the accuracy of the model for the 2nd sample.\n",
    "# 3. ...\n",
    "loss = -prob[torch.arange(5), Y].log().mean()\n",
    "loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T00:25:19.401746Z",
     "start_time": "2024-02-26T00:25:19.394826Z"
    }
   },
   "id": "187afca4e73ca484",
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0, 1, 2, 3, 4])"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T00:15:54.710836Z",
     "start_time": "2024-02-26T00:15:54.702948Z"
    }
   },
   "id": "8704804af3542a5d",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182437, 3]) torch.Size([182437])\n",
      "torch.Size([22781, 3]) torch.Size([22781])\n",
      "torch.Size([22928, 3]) torch.Size([22928])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  for w in words:\n",
    "\n",
    "    #print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      #print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])# training set\n",
    "Xdev, Ydev = build_dataset(words[n1:n2]) # validation set\n",
    "Xte, Yte = build_dataset(words[n2:])# test set"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T00:31:54.943193Z",
     "start_time": "2024-02-26T00:31:54.669968Z"
    }
   },
   "id": "45adb8c9b097a7a7",
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C = torch.randn((27, 10), generator=g)\n",
    "\n",
    "# Here we define a MLP with two layers. The MLP takes a 30-D input and produces a 27-D output.\n",
    "# A layer of 200 neurons\n",
    "W1 = torch.randn((30, 200), generator=g)\n",
    "b1 = torch.randn(200, generator=g)\n",
    "\n",
    "# A layer of 27 neurons.\n",
    "W2 = torch.randn((200, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T00:31:56.653208Z",
     "start_time": "2024-02-26T00:31:56.646174Z"
    }
   },
   "id": "d24842dda7f3bfd4",
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "11897"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters) # number of parameters in total"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T00:31:58.386014Z",
     "start_time": "2024-02-26T00:31:58.380580Z"
    }
   },
   "id": "c4862008376c1ff4",
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T00:32:00.147969Z",
     "start_time": "2024-02-26T00:32:00.140003Z"
    }
   },
   "id": "2bdabdbcc80fc323",
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "lri = []\n",
    "lossi = []\n",
    "stepi = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T00:32:01.801884Z",
     "start_time": "2024-02-26T00:32:01.795702Z"
    }
   },
   "id": "e30c688266bc665e",
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.018911123275757\n",
      "2.3627350330352783\n",
      "2.459622621536255\n",
      "2.814265251159668\n",
      "2.1975536346435547\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "  \n",
    "  # minibatch construct\n",
    "  \n",
    "  # torch.randint: returns a tensor filled with random integers generated uniformly between the specified lower and upper bounds.\n",
    "  # 0: This is the lower bound (inclusive) for the range of random integers. It indicates that the random integers generated will be greater than or equal to 0.\n",
    "  # Xtr.shape[0]: This represents the upper bound (exclusive) of the range of random integers. \n",
    "  # Xtr.shape[0] is the total number of samples in the training dataset (Xtr).\n",
    "  # (32,): This is a tuple specifying the size of the output tensor. In this case, the output tensor will contain 32 random integers. The comma is necessary to indicate that this is a single-element tuple\n",
    "  # ix: [1,32]. \n",
    "  ix = torch.randint(0, Xtr.shape[0], (32,))\n",
    "  # print(ix) # ix is the index of a sample or a set of indexes in a batch of sample (batch size=32)\n",
    "  # forward pass\n",
    "  input = Xtr[ix] # a sample or a batch of sample. Each sample is a context (len=3)\n",
    "  # print(Xtr[ix].shape) \n",
    "  emb = C[Xtr[ix]] # (32, 3, 10) # create 10-D embeddings for each sample\n",
    "  # print(emb.shape)\n",
    "  h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 200)\n",
    "  logits = h @ W2 + b2 # (32, 27)\n",
    "  loss = F.cross_entropy(logits, Ytr[ix])\n",
    "  print(loss.item())\n",
    "  # \n",
    "  # backward pass\n",
    "  for p in parameters:\n",
    "    p.grad = None\n",
    "  loss.backward()\n",
    "\n",
    "  # update\n",
    "  #lr = lrs[i]\n",
    "  lr = 0.1 if i < 100000 else 0.01\n",
    "  for p in parameters:\n",
    "    p.data += -lr * p.grad\n",
    "\n",
    "  # track stats\n",
    "  #lri.append(lre[i])\n",
    "  stepi.append(i)\n",
    "  lossi.append(loss.log10().item())\n",
    "\n",
    "#print(loss.item())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T00:48:30.406132Z",
     "start_time": "2024-02-26T00:48:30.396502Z"
    }
   },
   "id": "53296e06f0d6ab3f",
   "execution_count": 84
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5878899097442627\n",
      "2.2648394107818604\n",
      "2.28810715675354\n",
      "2.794795513153076\n",
      "2.243070363998413\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "  batch_size = 32\n",
    "  training_set_size = Xtr.shape[0]\n",
    "  ix = torch.randint(0, training_set_size, (batch_size,))\n",
    "  \n",
    "  input = Xtr[ix]\n",
    "  true_output =  Ytr[ix]\n",
    "  emb = C[input]\n",
    "  h = torch.tanh(emb.view(-1,30) @ W1 + b1) # (batch_size * 200)\n",
    "  h2 = h @ W2 + b2 # (batch_size * 27)\n",
    "  logits = h2\n",
    "  \n",
    "  loss = F.cross_entropy(logits, true_output)\n",
    "  print(loss.item())\n",
    "  \n",
    "  # backward pass\n",
    "  for p in parameters:\n",
    "    p.grad = None\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  #lr = lrs[i]\n",
    "  lr = 0.1 if i < 100000 else 0.01\n",
    "  for p in parameters:\n",
    "    p.data += -lr * p.grad"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T00:55:49.763297Z",
     "start_time": "2024-02-26T00:55:49.755764Z"
    }
   },
   "id": "b7c774b6ffa2a059",
   "execution_count": 91
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "922456545206b06c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
